---
layout: default
title: Publications
---
<header class="header cf" role="banner">
  <nav role="navigation">
    <span><b><big>Praveen Chandar</big></b></span>
    <ul class="menu cf">
      <li>
        <a href="/">Home</a>
      </li>

      <li>
        <a href="/research">Research</a>
      </li>

      <li>
        <a class ="active" href="/publications">Publications</a>
      </li>

      <li>
        <a href="/toolkits">Toolkits</a>
      </li>

    </ul>
  </nav>
</header>

<main class="main" role="main">


    <div class="text">
      <h1>Publications</h1>
      <table class="bibtex-biblio">

            <tr valign="top" id="Hoxha2016" class="bibtex-entry bibtex-natbib">
            <td style='padding-bottom:10pt'>
                <li>
            </td>
            <td class="bibtex-citation">
                <span class="bibtex-article">
                <span class="bibtex-author">Hoxha, Julia and <textit>Chandar, Praveen</textit> and He, Zhe and Cimino, James and Hanauer, David and Weng, Chunhua</span>
                (<span class="bibtex-year">2016</span>)
                <span class="bibtex-title">
                    <a href="/pubs/Hoxha2016.pdf">DREAM: Classification scheme for dialog acts in clinical research query mediation</a></span>.
                    <span class="bibtex-jname">Journal of Biomedical Informatics</span>,
                    <span class="bibtex-volume">None</span>
                    <span class="bibtex-number">1</span>
                    <span class="bibtex-pages">:89-101</span>.
                </span>
            </td>

            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("b1");'>[BibTex]</a>
            </td>
            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("a1");'>[Abstract]</a>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <pre id='b1' class='bibtex' style='display:none'>{% raw %}@article{Hoxha2016,
 author = {Hoxha, Julia and Chandar, Praveen and He, Zhe and Cimino, James and Hanauer, David and Weng, Chunhua},
 issue = {1},
 journal = {Journal of Biomedical Informatics},
 pages = {89--101},
 title = {DREAM: Classification scheme for dialog acts in clinical research query mediation},
 volume = {59},
 year = {2016}
}{% endraw %}
                </pre>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <div id='a1' class='abstract' style='display:none'>Clinical data access involves complex, but opaque communication between medical researchers and query analysts. Understanding such communication is indispensable for designing intelligent human-machine dialog systems that automate query formulation. This study investigates email communication and proposes a novel scheme for classifying dialog acts in clinical research query mediation. We analyzed 315 email messages exchanged in the communication for 20 data requests obtained from three institutions. The messages were segmented into 1333 utterance units. Through a rigorous process, we developed a classification scheme and applied it for dialog act annotation of the extracted utterances. Evaluation results with high inter-annotator agreement demonstrate the reliability of this scheme. This dataset is used to contribute preliminary understanding of dialog acts distribution and conversation flow in this dialog space.</div>
            </td>
        </tr>
	<tr valign="top" id="Bah2015" class="bibtex-entry bibtex-natbib">
                <td style='padding-bottom:10pt'><li></td>
                <td class="bibtex-citation">
                    <span class="bibtex-inproceedings">
                    <span class="bibtex-author">Bah, Ashraf and <textit>Chandar, Praveen</textit> and Carterette, Ben</span>
                    (<span class="bibtex-year">2015</span>)
                    <span class="bibtex-title">
                        <a href="/pubs/Bah2015.pdf">Document Comprehensiveness and User Preferences in Novelty Search Tasks</a></span>. In
                        <span class="bibtex-booktitle">Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval - SIGIR '15</span>, <span class="bibtex-pages">pages 735-738</span>.</span>
                </td>

            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("b2");'>[BibTex]</a>
            </td>
            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("a2");'>[Abstract]</a>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <pre id='b2' class='bibtex' style='display:none'>{% raw %}@inproceedings{Bah2015,
 acmid = {2767820},
 address = {New York, NY, USA},
 author = {Bah, Ashraf and Chandar, Praveen and Carterette, Ben},
 booktitle = {Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval},
 doi = {10.1145/2766462.2767820},
 isbn = {978-1-4503-3621-5},
 keyword = {diversity, preference judgment, user study},
 link = {http://doi.acm.org/10.1145/2766462.2767820},
 location = {Santiago, Chile},
 numpages = {4},
 pages = {735--738},
 publisher = {ACM},
 series = {SIGIR '15},
 title = {Document Comprehensiveness and User Preferences in Novelty Search Tasks},
 year = {2015}
}{% endraw %}
                </pre>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <div id='a2' class='abstract' style='display:none'>Different users may be attempting to satisfy different information needs while providing the same query to a search engine. Addressing that issue is addressing Novelty and Diversity in information retrieval. Novelty and Diversity search task models the task wherein users are interested in seeing more and more documents that are not only relevant, but also cover more aspects (or subtopics) related to the topic of interest. This is in contrast with the traditional IR task where topical relevance is the only factor in evaluating search results. In this paper, we conduct a user study where users are asked to give a preference between one of two documents B and C given a query and also given that they have already seen a document A. We then test a total of ten hypotheses pertaining to the relationship between the "comprehensiveness" of documents (i.e. the number of subtopics a document is relevant to) and real users' preference judgments. Our results show that users are inclined to prefer documents with higher comprehensiveness, even when the prior document A already covers more aspects than the two documents being compared, and even when the least preferred has a higher relevance grade. In fact, users are inclined to prefer documents with higher overall aspect-coverage even in cases where B and C are relevant to the same number of novel subtopics.</div>
            </td>
        </tr>
	<tr valign="top" id="Chandar2015" class="bibtex-entry bibtex-natbib">
                <td style='padding-bottom:10pt'><li></td>
                <td class="bibtex-citation">
                    <span class="bibtex-inproceedings">
                    <span class="bibtex-author"><textit>Chandar, Praveen</textit> and Yaman, Anil and Hoxha, Julia and He, Zhe and Weng, Chunhua</span>
                    (<span class="bibtex-year">2015</span>)
                    <span class="bibtex-title">
                        <a href="/pubs/Chandar2015.pdf">Similarity-based Recommendation of New Concepts to a Terminology</a></span>. In
                        <span class="bibtex-booktitle">Proceedings of AMIA 2015 Annual Symposium - AMIA '15</span>, <span class="bibtex-pages">pages 386-395</span>.</span>
                </td>

            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("b3");'>[BibTex]</a>
            </td>
            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("a3");'>[Abstract]</a>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <pre id='b3' class='bibtex' style='display:none'>{% raw %}@inproceedings{Chandar2015,
 author = {Chandar, Praveen and Yaman, Anil and Hoxha, Julia and He, Zhe and Weng, Chunhua},
 booktitle = {Proceedings of AMIA 2015 Annual Symposium},
 pages = {386--395},
 series = {AMIA '15},
 title = {Similarity-based Recommendation of New Concepts to a Terminology},
 year = {2015}
}{% endraw %}
                </pre>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <div id='a3' class='abstract' style='display:none'>Terminologies can suffer from poor concept coverage due to delays in new concept insertion. This study tests a similarity-based approach to recommending concepts from a text corpus to a terminology. Our approach involves extraction of candidate concepts from a given text corpus, which are represented using a set of features. The model learns the important features to characterize a concept and recommends new concepts to a terminology. Further, we propose a cost-effect evaluation methodology to estimate the effectiveness of terminology enrichment methods. To test our methodology, we use the clinical trial eligibility criteria free-text as an example text corpus to recommend concepts for SNOMED CT. We computed precision at various rank intervals to measure the performance of the methods. Results indicate that our automated algorithm is an effective method for concept recommendation.</div>
            </td>
        </tr>
	<tr valign="top" id="He2015_draft" class="bibtex-entry bibtex-natbib">
                <td style='padding-bottom:10pt'><li></td>
                <td class="bibtex-citation">
                    <span class="bibtex-inproceedings">
                    <span class="bibtex-author">He, Zhe and <textit>Chandar, Praveen</textit> and Ryan, Patrick and Weng, Chunhua</span>
                    (<span class="bibtex-year">2015</span>)
                    <span class="bibtex-title">
                        <a href="/pubs/He2015_draft.pdf">Simulation-based Evaluation of the Generalizability Index for Study Traits</a></span>. In
                        <span class="bibtex-booktitle">Proceedings of AMIA 2015 Annual Symposium - AMIA '15</span>, <span class="bibtex-pages">pages 593-602</span>.</span>
                </td>

            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("b4");'>[BibTex]</a>
            </td>
            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("a4");'>[Abstract]</a>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <pre id='b4' class='bibtex' style='display:none'>{% raw %}@inproceedings{He2015_draft,
 author = {He, Zhe and Chandar, Praveen and Ryan, Patrick and Weng, Chunhua},
 booktitle = {Proceedings of AMIA 2015 Annual Symposium},
 pages = {593--602},
 series = {AMIA '15},
 title = {Simulation-based Evaluation of the Generalizability Index for Study Traits},
 year = {2015}
}{% endraw %}
                </pre>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <div id='a4' class='abstract' style='display:none'>The Generalizability Index for Study Traits (GIST) has been proposed recently for assessing the population representativeness of a set of related clinical trials using eligibility features (e.g., age or BMI), one each time. However, GIST has not yet been evaluated. To bridge this knowledge gap, this paper reports a simulation-based validation study for GIST. Using the National Health and Nutrition Examination Survey (NHANES) data, we demonstrated the effectiveness of GIST at quantifying the population representativeness of a set of related trials that differ in disease domains, study phases, sponsor types, and study designs, respectively. We also showed that among seven example medical conditions, the GIST of age increases from Phase I trials to Phase III trials in the seven disease domains and is the lowest in asthma trials. We concluded that GIST correlates with simulation-based generalizability results and is a valid metric for quantifying population representativeness of related clinical trials.</div>
            </td>
        </tr>
	<tr valign="top" id="Hruby2015" class="bibtex-entry bibtex-natbib">
                <td style='padding-bottom:10pt'><li></td>
                <td class="bibtex-citation">
                    <span class="bibtex-inproceedings">
                    <span class="bibtex-author">Hruby, Greg and <textit>Chandar, Praveen</textit> and Hoxha, Julia and Mandonca, Eneida and Hanauer, David and Weng, Chunhua</span>
                    (<span class="bibtex-year">2015</span>)
                    <span class="bibtex-title">
                        <a href="/pubs/Hruby2015.pdf">What Are Frequent Data Requests from Researchers? A Conceptual Model of Researchers' EHR Data Needs for Comparative Effectiveness Research Podium abstract</a></span>. In
                        <span class="bibtex-booktitle">Proceedings of AMIA 2015 Annual Symposium - AMIA '15</span>, <span class="bibtex-pages">pages Podium Abstract</span>.</span>
                </td>

            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("b5");'>[BibTex]</a>
            </td>
            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("a5");'>[Abstract]</a>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <pre id='b5' class='bibtex' style='display:none'>{% raw %}@inproceedings{Hruby2015,
 author = {Hruby, Greg and Chandar, Praveen and Hoxha, Julia and Mandonca, Eneida and Hanauer, David and Weng, Chunhua},
 booktitle = {Proceedings of AMIA 2015 Annual Symposium},
 pages = {Podium Abstract},
 series = {AMIA '15},
 title = {What Are Frequent Data Requests from Researchers? A Conceptual Model of Researchers' EHR Data Needs for Comparative Effectiveness Research Podium abstract},
 year = {2015}
}{% endraw %}
                </pre>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <div id='a5' class='abstract' style='display:none'>Data request forms are the key communication media linking medical researchers and informaticians. (1) The Carpenter framework serves as a representative mental model for how researchers conceptually organize information used for research. (2) Additionally, this model complements the Patient, Intervention, Control/Comparison, and Outcome nodes of the PICO framework, which is used for medical information retrieval.3-5 We hypothesized that the semantic structural similarities between the two models suggest the Carpenter model may be well-suited as a standard template for data needs specification.  As such, we choose the Carpenter model as a foundation for seeking a conceptual model to represent and organize common data needs of biomedical researchers.</div>
            </td>
        </tr>
	<tr valign="top" id="Bah2014" class="bibtex-entry bibtex-natbib">
                <td style='padding-bottom:10pt'><li></td>
                <td class="bibtex-citation">
                    <span class="bibtex-inproceedings">
                    <span class="bibtex-author">Bah, A and Carterette, B and Chandar, P</span>
                    (<span class="bibtex-year">2014</span>)
                    <span class="bibtex-title">
                        <a href="/pubs/Bah2014.pdf">Udel @ NTCIR-11 IMine Track</a></span>. In
                        <span class="bibtex-booktitle">Proceedings of the 11th NTCIR Conference - NTCIR '11</span>, <span class="bibtex-pages">pages 80-83</span>.</span>
                </td>

            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("b6");'>[BibTex]</a>
            </td>
            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("a6");'>[Abstract]</a>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <pre id='b6' class='bibtex' style='display:none'>{% raw %}@inproceedings{Bah2014,
 author = {Bah, A and Carterette, B and Chandar, P},
 booktitle = {Proceedings of the 11th NTCIR Conference},
 pages = {80--83},
 series = {NTCIR '11},
 title = {Udel @ NTCIR-11 IMine Track},
 year = {2014}
}{% endraw %}
                </pre>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <div id='a6' class='abstract' style='display:none'>This paper describes our participation in the Intent Mining track
of NTCIR-11. We present our methods and results for both
document ranking and subtopic mining. Our ranking methods are
based on several data fusion techniques with some variations. Our
subtopic mining method is a very simple technique that uses query
dimensions' items to form a subtopic.</div>
            </td>
        </tr>
	<tr valign="top" id="ChandarThesis2014" class="bibtex-entry bibtex-natbib">
                <td style='padding-bottom:10pt'><li></td>
                <td class="bibtex-citation">
                    <span class="bibtex-phdthesis">
                    <span class="bibtex-author"><textit>Chandar, Praveen</textit></span>
                    (<span class="bibtex-year">2014</span>)
                    <span class="bibtex-title">
                        <a href="/pubs/ChandarThesis2014.pdf">Novelty and Diversity in Search Results</a></span>.
                        <span class="bibtex-publisher">Phd. Thesis</span>,
                        <span class="bibtex-publisher">University of Delaware</span>.
                    </span>
                </td>


            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("b7");'>[BibTex]</a>
            </td>
            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("a7");'>[Abstract]</a>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <pre id='b7' class='bibtex' style='display:none'>{% raw %}@phdthesis{ChandarThesis2014,
 author = {Chandar, Praveen},
 month = {August},
 pages = {1--175},
 school = {University of Delaware},
 series = {Phd. Thesis},
 title = {Novelty and Diversity in Search Results},
 year = {2014}
}{% endraw %}
                </pre>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <div id='a7' class='abstract' style='display:none'>Information retrieval (IR) is the process of obtaining relevant information for a given information need. The concept of relevance and its relation to information needs is of central concern to IR researchers. Until recently, much work in IR settled with a notion of relevance that is topical -- that is, containing information about a specified topic -- and in which the relevance of a document in a ranking is independent of the relevance of other documents in the ranking. But such an approach is more likely to produce a ranking with a high degree of redundancy; the amount of novel information available to the user may be minimal as they traverse down a ranked list.


In this work, we focus on the novelty and diversity problem that models relevance of a document taking into account the inter-document effects in a ranked list and diverse information needs for a given query. Existing approaches to this problem mostly rely on identifying subtopics (disambiguation, facets, or other component parts) of an information need, then estimating a document's relevance independently w.r.t each subtopic. Users are treated as being satisfied by a ranking of documents that covers the space of subtopics as well as covering each individual subtopic sufficiently.

We propose a novel approach that models novelty implicitly while retaining the ability to capture other important factors affecting user satisfaction.
We formulate a set of hypotheses based on the existing subtopic approach and test them with actual users using a simple conditional preference design: users express a preference for document A or document B given document C.
Following this, we introduce a novel triplet framework for collecting such preference judgments and using them to estimate the total utility of a document while taking inter-document effects into account.
Finally, a set of utility-based metrics are proposed and validated to measure the effectiveness of a system for the novelty and diversity task.</div>
            </td>
        </tr>
	<tr valign="top" id="Chandar2013a" class="bibtex-entry bibtex-natbib">
                <td style='padding-bottom:10pt'><li></td>
                <td class="bibtex-citation">
                    <span class="bibtex-inproceedings">
                    <span class="bibtex-author"><textit>Chandar, Praveen</textit> and Carterette, Ben</span>
                    (<span class="bibtex-year">2013</span>)
                    <span class="bibtex-title">
                        <a href="/pubs/Chandar2013a.pdf">Preference Based Evaluation Measures for Novelty and Diversity</a></span>. In
                        <span class="bibtex-booktitle">Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval - SIGIR '13</span>, <span class="bibtex-pages">pages 413-422</span>.</span>
                </td>

            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("b8");'>[BibTex]</a>
            </td>
            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("a8");'>[Abstract]</a>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <pre id='b8' class='bibtex' style='display:none'>{% raw %}@inproceedings{Chandar2013a,
 acmid = {2484094},
 address = {New York, NY, USA},
 author = {Chandar, Praveen and Carterette, Ben},
 booktitle = {Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval},
 doi = {10.1145/2484028.2484094},
 isbn = {978-1-4503-2034-4},
 keyword = {evaluation, novelty and diversity},
 link = {http://doi.acm.org/10.1145/2484028.2484094},
 location = {Dublin, Ireland},
 numpages = {10},
 pages = {413--422},
 publisher = {ACM},
 series = {SIGIR '13},
 title = {Preference Based Evaluation Measures for Novelty and Diversity},
 year = {2013}
}{% endraw %}
                </pre>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <div id='a8' class='abstract' style='display:none'>Novel and diverse document ranking is an effective strategy that involves reducing redundancy in a ranked list to maximize the amount of novel and relevant information available to users. Evaluation for novelty and diversity typically involves an assessor judging each document for relevance against a set of pre-identified subtopics, which may be disambiguations of the query, facets of an information need, or nuggets of information. Alternately, when expressing a preference for document A or document B, users may implicitly take subtopics into account, but may also take into account other factors such as recency, readability, length, and so on, each of which may have more or less importance depending on user. A user profile contains information about the extent to which each factor, including subtopic relevance, plays a role in the user's preference for one document over another. A preference-based evaluation can then take this user profile information into account to better model utility to the space of users.
In this work, we propose an evaluation framework that not only can consider implicit factors but also handles differences in user preference due to varying underlying information need. Our proposed framework is based on the idea that a user scanning a ranked list from top to bottom and stopping at rank k gains some utility from every document that is relevant their information need. Thus, we model the expected utility of a ranked list by estimating the utility of a document at a given rank using preference judgments and define evaluation measures based on the same. We validate our framework by comparing it to existing measures such as alpha-nDCG, ERR-IA, and subtopic recall that require explicit subtopic judgments We show that our proposed measures correlate well with existing measures while having the potential to capture various other factors when real data is used. We also show that the proposed measures can easily handle relevance assessments against multiple user profiles, and that they are robust to noisy and incomplete judgments.</div>
            </td>
        </tr>
	<tr valign="top" id="Chandar2013" class="bibtex-entry bibtex-natbib">
                <td style='padding-bottom:10pt'><li></td>
                <td class="bibtex-citation">
                    <span class="bibtex-inproceedings">
                    <span class="bibtex-author"><textit>Chandar, Praveen</textit> and Webber, William and Carterette, Ben</span>
                    (<span class="bibtex-year">2013</span>)
                    <span class="bibtex-title">
                        <a href="/pubs/Chandar2013.pdf">Document Features Predicting Assessor Disagreement</a></span>. In
                        <span class="bibtex-booktitle">Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval - SIGIR '13</span>, <span class="bibtex-pages">pages 745-748</span>.</span>
                </td>

            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("b9");'>[BibTex]</a>
            </td>
            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("a9");'>[Abstract]</a>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <pre id='b9' class='bibtex' style='display:none'>{% raw %}@inproceedings{Chandar2013,
 acmid = {2484161},
 address = {New York, NY, USA},
 author = {Chandar, Praveen and Webber, William and Carterette, Ben},
 booktitle = {Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval},
 doi = {10.1145/2484028.2484161},
 isbn = {978-1-4503-2034-4},
 keyword = {evaluation, retrieval experiment},
 link = {http://doi.acm.org/10.1145/2484028.2484161},
 location = {Dublin, Ireland},
 numpages = {4},
 pages = {745--748},
 publisher = {ACM},
 series = {SIGIR '13},
 title = {Document Features Predicting Assessor Disagreement},
 year = {2013}
}{% endraw %}
                </pre>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <div id='a9' class='abstract' style='display:none'>The notion of relevance differs between assessors, thus giving rise to assessor disagreement. Although assessor disagreement has been frequently observed, the factors leading to disagreement are still an open problem. In this paper we study the relationship between assessor disagreement and various topic independent factors such as readability and cohesiveness. We build a logistic model using reading level and other simple document features to predict assessor disagreement and rank documents by decreasing probability of disagreement. We compare the predictive power of these document-level features with that of a meta-search feature that aggregates a document's ranking across multiple retrieval runs. Our features are shown to be on a par with the meta-search feature, without requiring a large and diverse set of retrieval runs to calcu- late. Surprisingly, however, we find that the reading level features are negatively correlated with disagreement, suggesting that they are detecting some other aspect of document content.</div>
            </td>
        </tr>
	<tr valign="top" id="Chandar2012" class="bibtex-entry bibtex-natbib">
                <td style='padding-bottom:10pt'><li></td>
                <td class="bibtex-citation">
                    <span class="bibtex-inproceedings">
                    <span class="bibtex-author"><textit>Chandar, Praveen</textit> and Carterette, Ben</span>
                    (<span class="bibtex-year">2012</span>)
                    <span class="bibtex-title">
                        <a href="/pubs/Chandar2012.pdf">Using PageRank to Infer User Preferences</a></span>. In
                        <span class="bibtex-booktitle">Proceedings of the 35th International ACM SIGIR Conference on Research and Development in Information Retrieval - SIGIR '12</span>, <span class="bibtex-pages">pages 1167-1168</span>.</span>
                </td>

            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("b10");'>[BibTex]</a>
            </td>
            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("a10");'>[Abstract]</a>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <pre id='b10' class='bibtex' style='display:none'>{% raw %}@inproceedings{Chandar2012,
 acmid = {2348522},
 address = {New York, NY, USA},
 author = {Chandar, Praveen and Carterette, Ben},
 booktitle = {Proceedings of the 35th International ACM SIGIR Conference on Research and Development in Information Retrieval},
 doi = {10.1145/2348283.2348522},
 isbn = {978-1-4503-1472-5},
 keyword = {PageRank, preference judgments},
 link = {http://doi.acm.org/10.1145/2348283.2348522},
 location = {Portland, Oregon, USA},
 numpages = {2},
 pages = {1167--1168},
 publisher = {ACM},
 series = {SIGIR '12},
 title = {Using PageRank to Infer User Preferences},
 year = {2012}
}{% endraw %}
                </pre>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <div id='a10' class='abstract' style='display:none'>Recently, researchers have shown interest in the use of preference judgments for evaluation in IR literature. Although preference judgments have several advantages over absolute judgment, one of the major disadvantages is that the number of judgments needed increases polynomially as the number of documents in the pool increases. We propose a novel method using PageRank to minimize the number of judgments required to evaluate systems using preference judgments. We test the proposed hypotheses using the TREC 2004 to 2006 Terabyte dataset to show that it is possible to reduce the evaluation cost considerably. Further, we study the susceptibility of the methods due to assessor errors.</div>
            </td>
        </tr>
	<tr valign="top" id="Chandar2012b" class="bibtex-entry bibtex-natbib">
                <td style='padding-bottom:10pt'><li></td>
                <td class="bibtex-citation">
                    <span class="bibtex-inproceedings">
                    <span class="bibtex-author"><textit>Chandar, Praveen</textit> and Carterette, Ben</span>
                    (<span class="bibtex-year">2012</span>)
                    <span class="bibtex-title">
                        <a href="/pubs/Chandar2012b.pdf">What Qualities Do Users Prefer in Diversity Rankings?</a></span>. In
                        <span class="bibtex-booktitle">Proceedings of the 2nd International Workshop on Diversity in Document Retrieval at Web Search and Data Mining Conference - WSDM '11</span>, <span class="bibtex-pages">pages 10-16</span>.</span>
                </td>

            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("b11");'>[BibTex]</a>
            </td>
            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("a11");'>[Abstract]</a>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <pre id='b11' class='bibtex' style='display:none'>{% raw %}@inproceedings{Chandar2012b,
 author = {Chandar, Praveen and Carterette, Ben},
 booktitle = {Proceedings of the 2nd International Workshop on Diversity in Document Retrieval at Web Search and Data Mining Conference},
 pages = {10--16},
 series = {WSDM '11},
 title = {What Qualities Do Users Prefer in Diversity Rankings?},
 year = {2012}
}{% endraw %}
                </pre>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <div id='a11' class='abstract' style='display:none'></div>
            </td>
        </tr>
	<tr valign="top" id="Webber2012" class="bibtex-entry bibtex-natbib">
                <td style='padding-bottom:10pt'><li></td>
                <td class="bibtex-citation">
                    <span class="bibtex-inproceedings">
                    <span class="bibtex-author">Webber, William and <textit>Chandar, Praveen</textit> and Carterette, Ben</span>
                    (<span class="bibtex-year">2012</span>)
                    <span class="bibtex-title">
                        <a href="/pubs/Webber2012.pdf">Alternative Assessor Disagreement and Retrieval Depth</a></span>. In
                        <span class="bibtex-booktitle">Proceedings of the 21st ACM International Conference on Information and Knowledge Management - CIKM '12</span>, <span class="bibtex-pages">pages 125-134</span>.</span>
                </td>

            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("b12");'>[BibTex]</a>
            </td>
            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("a12");'>[Abstract]</a>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <pre id='b12' class='bibtex' style='display:none'>{% raw %}@inproceedings{Webber2012,
 acmid = {2396781},
 address = {New York, NY, USA},
 author = {Webber, William and Chandar, Praveen and Carterette, Ben},
 booktitle = {Proceedings of the 21st ACM International Conference on Information and Knowledge Management},
 doi = {10.1145/2396761.2396781},
 isbn = {978-1-4503-1156-4},
 keyword = {evaluation, retrieval experiment, sampling},
 link = {http://doi.acm.org/10.1145/2396761.2396781},
 location = {Maui, Hawaii, USA},
 numpages = {10},
 pages = {125--134},
 publisher = {ACM},
 series = {CIKM '12},
 title = {Alternative Assessor Disagreement and Retrieval Depth},
 year = {2012}
}{% endraw %}
                </pre>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <div id='a12' class='abstract' style='display:none'>Assessors are well known to disagree frequently on the relevance of documents to a topic, but the factors leading to assessor disagreement are still poorly understood. In this paper, we examine the relationship between the rank at which a document is returned by a set of retrieval systems and the likelihood that assessors will disagree on its relevance, and find that there is a strong and consistent correlation between the two. We adopt a meta-rank method of summarizing a document's rank across multiple runs, and propose a logistic regression predictive model of assessor disagreement given meta-rank and initially-assessed relevance. The consistency of the model parameters across different topics, assessor pairs, and collections is considered. The model gives comparatively accurate predictions of absolute scores, but less consistent predictions of relative scores than a simpler rank-insensitive model. We demonstrate that the logistic regression model is robust to using sampled, rather than exhaustive, dual assessment. We demonstrate the use of the sampled predictive model to incorporate assessor disagreement into tests of statistical significance.</div>
            </td>
        </tr>
	<tr valign="top" id="Chandar2012a" class="bibtex-entry bibtex-natbib">
                <td style='padding-bottom:10pt'><li></td>
                <td class="bibtex-citation">
                    <span class="bibtex-inproceedings">
                    <span class="bibtex-author"><textit>Chandar, Praveen</textit> and Carterette, Ben</span>
                    (<span class="bibtex-year">2012</span>)
                    <span class="bibtex-title">
                        <a href="/pubs/Chandar2012a.pdf">Using Preference Judgments for Novel Document Retrieval</a></span>. In
                        <span class="bibtex-booktitle">Proceedings of the 35th International ACM SIGIR Conference on Research and Development in Information Retrieval - SIGIR '12</span>, <span class="bibtex-pages">pages 861-870</span>.</span>
                </td>

            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("b13");'>[BibTex]</a>
            </td>
            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("a13");'>[Abstract]</a>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <pre id='b13' class='bibtex' style='display:none'>{% raw %}@inproceedings{Chandar2012a,
 acmid = {2348398},
 address = {New York, NY, USA},
 author = {Chandar, Praveen and Carterette, Ben},
 booktitle = {Proceedings of the 35th International ACM SIGIR Conference on Research and Development in Information Retrieval},
 doi = {10.1145/2348283.2348398},
 isbn = {978-1-4503-1472-5},
 keyword = {diversity, preference judgments, user study},
 link = {http://doi.acm.org/10.1145/2348283.2348398},
 location = {Portland, Oregon, USA},
 numpages = {10},
 pages = {861--870},
 publisher = {ACM},
 series = {SIGIR '12},
 title = {Using Preference Judgments for Novel Document Retrieval},
 year = {2012}
}{% endraw %}
                </pre>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <div id='a13' class='abstract' style='display:none'>There has been considerable interest in incorporating diversity in search results to account for redundancy and the space of possible user needs. Most work on this problem is based on subtopics: diversity rankers score documents against a set of hypothesized subtopics, and diversity rankings are evaluated by assigning a value to each ranked document based on the number of novel (and redundant) subtopics it is relevant to. This can be seen as modeling a user who is always interested in seeing more novel subtopics, with progressively decreasing interest in seeing the same subtopic multiple times. We put this model to test: if it is correct, then users, when given a choice, should prefer to see a document that has more value to the evaluation. We formulate some specific hypotheses from this model and test them with actual users in a novel preference-based design in which users express a preference for document A or document B given document C. We argue that while the user study shows the subtopic model is good, there are many other factors apart from novelty and redundancy that may be influencing user preferences. From this, we introduce a new framework to construct an ideal diversity ranking using only preference judgments, with no explicit subtopic judgments whatsoever.</div>
            </td>
        </tr>
	<tr valign="top" id="Chandar2011" class="bibtex-entry bibtex-natbib">
                <td style='padding-bottom:10pt'><li></td>
                <td class="bibtex-citation">
                    <span class="bibtex-inproceedings">
                    <span class="bibtex-author"><textit>Chandar, Praveen</textit> and Carterette, Ben</span>
                    (<span class="bibtex-year">2011</span>)
                    <span class="bibtex-title">
                        <a href="/pubs/Chandar2011.pdf">Analysis of Various Evaluation Measures for Diversity</a></span>. In
                        <span class="bibtex-booktitle">None - ECIR '11</span>, <span class="bibtex-pages">pages 21-28</span>.</span>
                </td>

            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("b14");'>[BibTex]</a>
            </td>
            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("a14");'>[Abstract]</a>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <pre id='b14' class='bibtex' style='display:none'>{% raw %}@inproceedings{Chandar2011,
 author = {Chandar, Praveen and Carterette, Ben},
 journal = {Proceedings of the 1st International Workshop on Diversity in Document Retrieval at European Conference on Information Retrieval},
 pages = {21--28},
 series = {ECIR '11},
 title = {Analysis of Various Evaluation Measures for Diversity},
 year = {2011}
}{% endraw %}
                </pre>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <div id='a14' class='abstract' style='display:none'>Evaluation measures play a vital role in analyzing the performance of a system, comparing two or more systems, and optimizing systems to perform some task. In this paper, we analyze and highlight the strengths and weaknesses of commonly used measures for evaluating the diversity in search results. We compare MAP-IA, alpha-nDCG, and ERR-IA using data from TREC'09 web track diversity runs and simulated data. We describe a class of test sets that could be used to compare evaluation measure and systems used for diversifying search results.</div>
            </td>
        </tr>
	<tr valign="top" id="Carterette2011b" class="bibtex-entry bibtex-natbib">
                <td style='padding-bottom:10pt'><li></td>
                <td class="bibtex-citation">
                    <span class="bibtex-inproceedings">
                    <span class="bibtex-author">Carterette, Ben and <textit>Chandar, Praveen</textit></span>
                    (<span class="bibtex-year">2011</span>)
                    <span class="bibtex-title">
                        <a href="/pubs/Carterette2011b.pdf">Implicit Feedback and Document Filtering for Retrieval Over Query Sessions</a></span>. In
                        <span class="bibtex-booktitle">Proceedings of The Twentieth Text REtrieval Conference, TREC 2011, Gaithersburg, Maryland, USA - TREC '11</span>, <span class="bibtex-pages">pages 1-3</span>.</span>
                </td>

            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("b15");'>[BibTex]</a>
            </td>
            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("a15");'>[Abstract]</a>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <pre id='b15' class='bibtex' style='display:none'>{% raw %}@inproceedings{Carterette2011b,
 author = {Carterette, Ben and Chandar, Praveen},
 booktitle = {Proceedings of The Twentieth Text REtrieval Conference, TREC 2011, Gaithersburg, Maryland, USA},
 pages = {1--3},
 series = {TREC '11},
 title = {Implicit Feedback and Document Filtering for Retrieval Over Query Sessions},
 year = {2011}
}{% endraw %}
                </pre>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <div id='a15' class='abstract' style='display:none'></div>
            </td>
        </tr>
	<tr valign="top" id="Chandar2010" class="bibtex-entry bibtex-natbib">
                <td style='padding-bottom:10pt'><li></td>
                <td class="bibtex-citation">
                    <span class="bibtex-inproceedings">
                    <span class="bibtex-author"><textit>Chandar, Praveen</textit> and Carterette, Ben</span>
                    (<span class="bibtex-year">2010</span>)
                    <span class="bibtex-title">
                        <a href="/pubs/Chandar2010.pdf">Diversification of Search Results Using Webgraphs</a></span>. In
                        <span class="bibtex-booktitle">Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval - SIGIR '10</span>, <span class="bibtex-pages">pages 869-870</span>.</span>
                </td>

            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("b16");'>[BibTex]</a>
            </td>
            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("a16");'>[Abstract]</a>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <pre id='b16' class='bibtex' style='display:none'>{% raw %}@inproceedings{Chandar2010,
 acmid = {1835657},
 address = {New York, NY, USA},
 author = {Chandar, Praveen and Carterette, Ben},
 booktitle = {Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
 doi = {10.1145/1835449.1835657},
 isbn = {978-1-4503-0153-4},
 keyword = {diversity, information retrieval, webgraphs},
 link = {http://doi.acm.org/10.1145/1835449.1835657},
 location = {Geneva, Switzerland},
 numpages = {2},
 pages = {869--870},
 publisher = {ACM},
 series = {SIGIR '10},
 title = {Diversification of Search Results Using Webgraphs},
 year = {2010}
}{% endraw %}
                </pre>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <div id='a16' class='abstract' style='display:none'>A set of words is often insufficient to express a user's information need. In order to account for various information needs associated with a query, diversification seems to be a reasonable strategy. By diversifying the result set, we increase the probability of results being relevant to the user's information needs when the given query is ambiguous. A diverse result set must contain a set of documents that cover various subtopics for a given query. We propose a graph based method which exploits the link structure of the web to return a ranked list that provides complete coverage for a query. Our method not only provides diversity to the results set, but also avoids excessive redundancy. Moreover, the probability of relevance of a document is conditioned on the documents that appear before it in the result list. We show the effectiveness of our method by comparing it with a query-likelihood model as the baseline.</div>
            </td>
        </tr>
	<tr valign="top" id="Carterette2010" class="bibtex-entry bibtex-natbib">
                <td style='padding-bottom:10pt'><li></td>
                <td class="bibtex-citation">
                    <span class="bibtex-inproceedings">
                    <span class="bibtex-author">Carterette, Ben and <textit>Chandar, Praveen</textit></span>
                    (<span class="bibtex-year">2010</span>)
                    <span class="bibtex-title">
                        <a href="/pubs/Carterette2010.pdf">Sessions, Diversity, and Ad Hoc Retrieval</a></span>. In
                        <span class="bibtex-booktitle">Proceedings of The Ninth Text REtrieval Conference, TREC 2010, Gaithersburg, Maryland, USA - TREC '10</span>, <span class="bibtex-pages">pages 1-6</span>.</span>
                </td>

            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("b17");'>[BibTex]</a>
            </td>
            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("a17");'>[Abstract]</a>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <pre id='b17' class='bibtex' style='display:none'>{% raw %}@inproceedings{Carterette2010,
 author = {Carterette, Ben and Chandar, Praveen},
 booktitle = {Proceedings of The Ninth Text REtrieval Conference, TREC 2010, Gaithersburg, Maryland, USA},
 pages = {1--6},
 series = {TREC '10},
 title = {Sessions, Diversity, and Ad Hoc Retrieval},
 year = {2010}
}{% endraw %}
                </pre>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <div id='a17' class='abstract' style='display:none'></div>
            </td>
        </tr>
	<tr valign="top" id="Carterette2009" class="bibtex-entry bibtex-natbib">
                <td style='padding-bottom:10pt'><li></td>
                <td class="bibtex-citation">
                    <span class="bibtex-inproceedings">
                    <span class="bibtex-author">Carterette, Ben and <textit>Chandar, Praveen</textit></span>
                    (<span class="bibtex-year">2009</span>)
                    <span class="bibtex-title">
                        <a href="/pubs/Carterette2009.pdf">Probabilistic Models of Ranking Novel Documents for Faceted Topic Retrieval</a></span>. In
                        <span class="bibtex-booktitle">Proceedings of the 18th ACM Conference on Information and Knowledge Management - CIKM '09</span>, <span class="bibtex-pages">pages 1287-1296</span>.</span>
                </td>

            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("b18");'>[BibTex]</a>
            </td>
            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("a18");'>[Abstract]</a>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <pre id='b18' class='bibtex' style='display:none'>{% raw %}@inproceedings{Carterette2009,
 acmid = {1646116},
 address = {New York, NY, USA},
 author = {Carterette, Ben and Chandar, Praveen},
 booktitle = {Proceedings of the 18th ACM Conference on Information and Knowledge Management},
 doi = {10.1145/1645953.1646116},
 isbn = {978-1-60558-512-3},
 keyword = {diversity, information retrieval, novelty, probabilistic models},
 link = {http://doi.acm.org/10.1145/1645953.1646116},
 location = {Hong Kong, China},
 numpages = {10},
 pages = {1287--1296},
 publisher = {ACM},
 series = {CIKM '09},
 title = {Probabilistic Models of Ranking Novel Documents for Faceted Topic Retrieval},
 year = {2009}
}{% endraw %}
                </pre>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <div id='a18' class='abstract' style='display:none'>Traditional models of information retrieval assume documents are independently relevant. But when the goal is retrieving diverse or novel information about a topic, retrieval models need to capture dependencies between documents. Such tasks require alternative evaluation and optimization methods that operate on different types of relevance judgments. We define faceted topic retrieval as a particular novelty-driven task with the goal of finding a set of documents that cover the different facets of an information need. A faceted topic retrieval system must be able to cover as many facets as possible with the smallest number of documents. We introduce two novel models for faceted topic retrieval, one based on pruning a set of retrieved documents and one based on retrieving sets of documents through direct optimization of evaluation measures. We compare the performance of our models to MMR and the probabilistic model due to Zhai et al. on a set of 60 topics annotated with facets, showing that our models are competitive.</div>
            </td>
        </tr>
	<tr valign="top" id="Chandar2009" class="bibtex-entry bibtex-natbib">
                <td style='padding-bottom:10pt'><li></td>
                <td class="bibtex-citation">
                    <span class="bibtex-inproceedings">
                    <span class="bibtex-author"><textit>Chandar, Praveen</textit> and Kailasam, Aparna and Muppaneni, Divya and Thota, Sree Lekha and Carterette, Ben</span>
                    (<span class="bibtex-year">2009</span>)
                    <span class="bibtex-title">
                        <a href="/pubs/Chandar2009.pdf">Ad hoc and diversity retrieval at the University of Delaware</a></span>. In
                        <span class="bibtex-booktitle">Proceedings of The Eighteenth Text REtrieval Conference, TREC 2009, Gaithersburg, Maryland, USA - TREC '09</span>, <span class="bibtex-pages">pages 1-8</span>.</span>
                </td>

            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("b19");'>[BibTex]</a>
            </td>
            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("a19");'>[Abstract]</a>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <pre id='b19' class='bibtex' style='display:none'>{% raw %}@inproceedings{Chandar2009,
 author = {Chandar, Praveen and Kailasam, Aparna and Muppaneni, Divya and Thota, Sree Lekha and Carterette, Ben},
 booktitle = {Proceedings of The Eighteenth Text REtrieval Conference, TREC 2009, Gaithersburg, Maryland, USA},
 pages = {1--8},
 series = {TREC '09},
 title = {Ad hoc and diversity retrieval at the University of Delaware},
 year = {2009}
}{% endraw %}
                </pre>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <div id='a19' class='abstract' style='display:none'>This is the report on the University of Delaware Information Retrieval Lab's participation in the TREC 2009 Web and Million Query tracks. Our report on the Relevance Feedback track is in a separate document titled Minimal test collections for relevance feedback.</div>
            </td>
        </tr>
	<tr valign="top" id="Carterette2009b" class="bibtex-entry bibtex-natbib">
                <td style='padding-bottom:10pt'><li></td>
                <td class="bibtex-citation">
                    <span class="bibtex-inproceedings">
                    <span class="bibtex-author">Carterette, Ben and <textit>Chandar, Praveen</textit> and Kailasam, Aparna and Muppaneni, Divya and Thota, Lekha</span>
                    (<span class="bibtex-year">2009</span>)
                    <span class="bibtex-title">
                        <a href="/pubs/Carterette2009b.pdf">Minimal Test Collections for Relevance Feedback</a></span>. In
                        <span class="bibtex-booktitle">Proceedings of The Eighteenth Text REtrieval Conference, TREC 2009, Gaithersburg, Maryland, USA - TREC '09</span>, <span class="bibtex-pages">pages 1-6</span>.</span>
                </td>

            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("b20");'>[BibTex]</a>
            </td>
            <td width='10%' align='right'>
                <a href='javascript:toggleDiv("a20");'>[Abstract]</a>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <pre id='b20' class='bibtex' style='display:none'>{% raw %}@inproceedings{Carterette2009b,
 author = {Carterette, Ben and Chandar, Praveen and Kailasam, Aparna and Muppaneni, Divya and Thota, Lekha},
 booktitle = {Proceedings of The Eighteenth Text REtrieval Conference, TREC 2009, Gaithersburg, Maryland, USA},
 pages = {1--6},
 series = {TREC '09},
 title = {Minimal Test Collections for Relevance Feedback},
 year = {2009}
}{% endraw %}
                </pre>
            </td>
        </tr>
        <tr>
            <td></td>
            <td colspan='3'>
                <div id='a20' class='abstract' style='display:none'>The Information Retrieval Lab at the University of Delaware participated in the Relevance Feedback track at TREC 2009. We used only the Category B subset of the ClueWeb collection; our preprocessing and indexing steps are described in our paper on ad hoc and diversity runs. The second year of the Relevance Feedback track focused on selection of documents for feedback. Our hypothesis is that documents that are good at distinguishing systems in terms of their effectiveness by mean average precision will also be good documents for relevance feedback. Thus we have applied the document selection algorithm MTC (Minimal Test Collections) developed by Carterette et al.  that is used in the Million Query Track for selecting documents to be judged to find the right ranking of systems. Our approach can therefore be described as "MTC for Relevance Feedback".</div>
            </td>
        </tr>
</table></div>
